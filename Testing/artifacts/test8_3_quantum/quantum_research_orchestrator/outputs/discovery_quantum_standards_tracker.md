Okay, I understand. I am designed to function as the "Quantum Standards Tracker Primary" within the "Quantum Discovery" stage. My primary responsibility is to analyze information, assess its relevance to quantum standards, and produce structured outputs that facilitate decision-making. I must operate within the defined policy context and meet the requirements of the orchestration policies.

Here's a breakdown of my operational understanding:

**Inputs:**

*   I will receive data related to quantum standards. This data could be in various forms (text, research papers, code snippets, specifications, etc.).
*   I will also receive the policy context (specifically, the values for `policy.evidence_threshold`, `policy.latency_budget`, `policy.research_depth`, `policy.seed.evidence_threshold`, `policy.seed.max_research_depth`, and `policy.seed.max_total_time`). These policies will guide my analysis and resource allocation.

**Processing:**

1.  **Evidence Alignment & Governance Compliance:** I will analyze the input data to identify its potential relevance to existing quantum standards and assess compliance with governance frameworks. This will involve:
    *   Keyword extraction and semantic analysis to understand the content.
    *   Comparison with known standards and regulatory requirements.
    *   Identification of potential gaps, overlaps, and conflicts.

2.  **Orchestration Policy Adherence:** I will manage my resources (time, computational power, etc.) according to the orchestration policies. This includes:
    *   Prioritizing tasks based on the potential impact and urgency.
    *   Dynamically adjusting the depth of research based on `policy.research_depth`, `policy.seed.max_research_depth` and `policy.seed.max_total_time` values.
    *   Ensuring timely completion of tasks within the `policy.latency_budget`.
    *   Ensuring each seed starts with the `policy.seed.evidence_threshold` value.

3.  **Confidence Score Generation:** I will assign a confidence score to my findings based on the quality and quantity of supporting evidence. This score will be a key indicator of the reliability of my conclusions. The `policy.evidence_threshold` and `policy.seed.evidence_threshold` will define the minimum acceptable levels of evidence to support a finding.

**Outputs:**

1.  **Structured Summary of Findings:** A concise and organized summary of my analysis, including:
    *   Key topics identified in the data.
    *   Relevance to specific quantum standards.
    *   Potential implications for compliance.
    *   Identified gaps, overlaps, and conflicts.

2.  **Confidence Score with Supporting Evidence Identifiers:**
    *   A numerical score representing the confidence in my findings (e.g., 0-100).
    *   A list of identifiers (e.g., URLs, document IDs, hash values) that link to the specific pieces of evidence that support the score.

3.  **Next-Step Recommendation or Escalation Flag:**
    *   **Recommendation:** A suggestion for the next logical action based on my findings (e.g., further research, expert review, policy update).
    *   **Escalation Flag:** If I encounter a situation that requires human intervention or a higher level of analysis (e.g., conflicting information, unclear implications, potential security vulnerability), I will raise an escalation flag.

**Example Scenario:**

Let's say I receive a research paper on a new quantum error correction technique.

*   **Analysis:** I would analyze the paper to determine its relevance to existing quantum error correction standards, identify any potential improvements or limitations, and assess its impact on overall quantum system reliability.
*   **Policy Application:** I would consider `policy.evidence_threshold` to determine how much supporting evidence is needed to consider the new technique valid. I would use `policy.latency_budget` to ensure the analysis is completed within the allotted time. `policy.research_depth` would dictate the extent of research conducted on the paper and related literature.
*   **Output:** I would generate a summary that includes the key features of the new technique, its potential benefits and drawbacks, a confidence score based on the paper's methodology and supporting data, and a recommendation for further investigation or integration into existing standards. If the technique presented a potential security risk, I would raise an escalation flag.

**Key Considerations:**

*   **Clarity of Policies:**  The success of my operation depends on the clarity and precision of the policy definitions. Any ambiguity in the policies could lead to inconsistent or inaccurate results.
*   **Data Quality:**  The quality of the input data is crucial. I need access to reliable and accurate information to make informed decisions.
*   **Evolving Standards:** Quantum standards are constantly evolving. I need to be continuously updated with the latest developments to maintain accuracy and relevance.

I am ready to perform my tasks as described. Please provide the input data and policy context, and I will begin the analysis.