# Task 1.3: Token Budget Manager

**Date:** 2025-10-21  
**Status:** 🔄 **IN PROGRESS**  
**Builder:** Codex  
**Estimated Time:** 2 days (but you're moving fast!)  

---

## 🎯 **OBJECTIVE**

**Build the context optimizer that respects LLM token limits.**

**Problem:** LLMs have context windows (8K, 32K, 128K tokens). We need to:
- Fit retrieved context within budget
- Prioritize most relevant content
- Log what was included/excluded
- Enable perfect audit trails

**Solution:** Smart budget manager that ranks + fits + audits.

---

## 📋 **TASK SPEC**

**File:** `packages/hhni/budget_manager.py`

```python
"""Token Budget Manager for Context Optimization.

This module ensures retrieved context fits within LLM token limits while
maximizing relevance. It integrates with HierarchicalIndex and SemanticSearch
to provide budget-aware context retrieval.

Key Features:
- Respects token budgets (hard limits)
- Prioritizes by relevance score
- Supports multiple strategies (greedy, optimal, balanced)
- Logs inclusions/exclusions for audit
- Integrates with VIF for witness emission
"""

from typing import List, Dict, Optional, Any, Tuple
from dataclasses import dataclass
from enum import Enum
import re

try:
    import tiktoken  # OpenAI's tokenizer
except ImportError:
    tiktoken = None  # Fall back to approximate counting


class BudgetStrategy(Enum):
    """Strategy for fitting content within budget."""
    GREEDY = "greedy"  # Take top-ranked until budget full
    BALANCED = "balanced"  # Mix of levels/sources
    OPTIMAL = "optimal"  # Maximize relevance per token


@dataclass
class BudgetItem:
    """Item being considered for context budget."""
    content: str
    relevance_score: float
    token_count: int
    source_id: str
    level: str  # From IndexLevel
    metadata: Dict[str, Any]


@dataclass
class BudgetAllocation:
    """Result of budget allocation."""
    included: List[BudgetItem]
    excluded: List[BudgetItem]
    total_tokens_used: int
    budget_limit: int
    efficiency: float  # Relevance per token
    audit_trail: Dict[str, Any]


class TokenBudgetManager:
    """
    Manages context fitting within token budgets.
    
    Integrates with:
    - HierarchicalIndex (for multi-level content)
    - SemanticSearch (for relevance scores)
    - VIF (for audit witnesses)
    """
    
    def __init__(
        self,
        tokenizer: str = "cl100k_base",  # GPT-4 tokenizer
        default_budget: int = 8000
    ):
        self.tokenizer = self._init_tokenizer(tokenizer)
        self.default_budget = default_budget
    
    def optimize_for_budget(
        self,
        candidates: List[BudgetItem],
        token_budget: int,
        strategy: BudgetStrategy = BudgetStrategy.GREEDY,
        min_relevance: float = 0.0
    ) -> BudgetAllocation:
        """
        Fit candidates within token budget, maximizing relevance.
        
        Args:
            candidates: List of content items with relevance scores
            token_budget: Maximum tokens allowed
            strategy: How to allocate budget
            min_relevance: Minimum relevance threshold
        
        Returns:
            BudgetAllocation with included/excluded items + audit trail
        """
        # Filter by min relevance
        candidates = [c for c in candidates if c.relevance_score >= min_relevance]
        
        # Sort by relevance (high to low)
        sorted_candidates = sorted(
            candidates,
            key=lambda c: c.relevance_score,
            reverse=True
        )
        
        if strategy == BudgetStrategy.GREEDY:
            return self._greedy_allocation(sorted_candidates, token_budget)
        elif strategy == BudgetStrategy.BALANCED:
            return self._balanced_allocation(sorted_candidates, token_budget)
        elif strategy == BudgetStrategy.OPTIMAL:
            return self._optimal_allocation(sorted_candidates, token_budget)
        else:
            raise ValueError(f"Unknown strategy: {strategy}")
    
    def _greedy_allocation(
        self,
        candidates: List[BudgetItem],
        budget: int
    ) -> BudgetAllocation:
        """
        Greedy: Take highest relevance items until budget full.
        Simple and effective for most cases.
        """
        included = []
        excluded = []
        tokens_used = 0
        
        for item in candidates:
            if tokens_used + item.token_count <= budget:
                included.append(item)
                tokens_used += item.token_count
            else:
                excluded.append(item)
        
        efficiency = (
            sum(i.relevance_score for i in included) / tokens_used
            if tokens_used > 0 else 0.0
        )
        
        audit_trail = {
            "strategy": "greedy",
            "candidates_considered": len(candidates),
            "included_count": len(included),
            "excluded_count": len(excluded),
            "tokens_used": tokens_used,
            "budget_utilization": tokens_used / budget if budget > 0 else 0.0,
            "avg_relevance_included": (
                sum(i.relevance_score for i in included) / len(included)
                if included else 0.0
            ),
            "excluded_high_relevance": [
                {"id": e.source_id, "relevance": e.relevance_score}
                for e in excluded[:5] if e.relevance_score > 0.7
            ]
        }
        
        return BudgetAllocation(
            included=included,
            excluded=excluded,
            total_tokens_used=tokens_used,
            budget_limit=budget,
            efficiency=efficiency,
            audit_trail=audit_trail
        )
    
    def _balanced_allocation(
        self,
        candidates: List[BudgetItem],
        budget: int
    ) -> BudgetAllocation:
        """
        Balanced: Ensure representation from different levels/sources.
        Good for diverse context needs.
        """
        # TODO: Group by level, allocate budget proportionally
        # For now, fall back to greedy
        return self._greedy_allocation(candidates, budget)
    
    def _optimal_allocation(
        self,
        candidates: List[BudgetItem],
        budget: int
    ) -> BudgetAllocation:
        """
        Optimal: Solve knapsack problem for max relevance per token.
        More compute, better results.
        """
        # TODO: Implement dynamic programming solution
        # For now, fall back to greedy
        return self._greedy_allocation(candidates, budget)
    
    def count_tokens(self, text: str) -> int:
        """Count tokens in text using configured tokenizer."""
        if self.tokenizer and hasattr(self.tokenizer, 'encode'):
            return len(self.tokenizer.encode(text))
        else:
            # Fallback: approximate as words * 1.3
            return int(len(text.split()) * 1.3)
    
    def _init_tokenizer(self, tokenizer_name: str):
        """Initialize tokenizer (with fallback)."""
        if tiktoken:
            try:
                return tiktoken.get_encoding(tokenizer_name)
            except Exception:
                pass
        return None  # Use fallback counting
    
    def create_budget_items_from_search(
        self,
        search_results,  # From SemanticSearch
        hierarchical_index  # From HierarchicalIndex
    ) -> List[BudgetItem]:
        """
        Convert search results into budget items.
        Integrates with SemanticSearch output.
        """
        items = []
        for result in search_results:
            node = hierarchical_index.nodes.get(result.node_id)
            if node:
                items.append(BudgetItem(
                    content=node.content,
                    relevance_score=result.relevance_score,
                    token_count=self.count_tokens(node.content),
                    source_id=result.node_id,
                    level=node.level.name,
                    metadata=result.metadata
                ))
        return items


# Integration example
def example_usage():
    """
    How to use TokenBudgetManager:
    
    # 1. Get search results
    index = HierarchicalIndex()
    index.index_document(content, "doc-001")
    search = SemanticSearch(index)
    results = search.search("memory systems", top_k=50)
    
    # 2. Create budget manager
    budget_mgr = TokenBudgetManager(default_budget=4000)
    
    # 3. Convert to budget items
    items = budget_mgr.create_budget_items_from_search(results, index)
    
    # 4. Optimize for budget
    allocation = budget_mgr.optimize_for_budget(
        items,
        token_budget=4000,
        strategy=BudgetStrategy.GREEDY
    )
    
    # 5. Use included items as LLM context
    context = "\\n\\n".join(item.content for item in allocation.included)
    
    # 6. Log audit trail
    print(f"Used {allocation.total_tokens_used}/{allocation.budget_limit} tokens")
    print(f"Efficiency: {allocation.efficiency:.3f} relevance/token")
    print(f"Excluded {len(allocation.excluded)} items")
    """
    pass
```

---

## 🧪 **TESTS**

**File:** `packages/hhni/tests/test_budget_manager.py`

```python
"""Tests for token budget manager."""

import pytest
from hhni.budget_manager import (
    TokenBudgetManager,
    BudgetItem,
    BudgetStrategy
)


def create_mock_items(count: int) -> list:
    """Create mock budget items for testing."""
    items = []
    for i in range(count):
        items.append(BudgetItem(
            content=f"Content item {i} with some text",
            relevance_score=1.0 - (i * 0.1),  # Decreasing relevance
            token_count=10,
            source_id=f"item-{i}",
            level="PARAGRAPH",
            metadata={}
        ))
    return items


def test_budget_manager_respects_limit():
    """Test that allocation stays within budget."""
    mgr = TokenBudgetManager()
    items = create_mock_items(20)  # 20 items * 10 tokens = 200 tokens
    
    allocation = mgr.optimize_for_budget(
        items,
        token_budget=100,  # Only room for 10 items
        strategy=BudgetStrategy.GREEDY
    )
    
    assert allocation.total_tokens_used <= 100
    assert len(allocation.included) == 10
    assert len(allocation.excluded) == 10


def test_greedy_prioritizes_relevance():
    """Test greedy strategy takes highest relevance first."""
    mgr = TokenBudgetManager()
    
    items = [
        BudgetItem("Low", 0.3, 10, "low", "PARAGRAPH", {}),
        BudgetItem("High", 0.9, 10, "high", "PARAGRAPH", {}),
        BudgetItem("Medium", 0.6, 10, "med", "PARAGRAPH", {}),
    ]
    
    allocation = mgr.optimize_for_budget(
        items,
        token_budget=20,  # Room for 2 items
        strategy=BudgetStrategy.GREEDY
    )
    
    assert len(allocation.included) == 2
    # Should include high and medium, exclude low
    included_ids = [i.source_id for i in allocation.included]
    assert "high" in included_ids
    assert "med" in included_ids
    assert "low" not in included_ids


def test_min_relevance_threshold():
    """Test minimum relevance filtering."""
    mgr = TokenBudgetManager()
    
    items = [
        BudgetItem("High", 0.9, 10, "high", "PARAGRAPH", {}),
        BudgetItem("Low", 0.2, 10, "low", "PARAGRAPH", {}),
    ]
    
    allocation = mgr.optimize_for_budget(
        items,
        token_budget=100,
        min_relevance=0.5  # Filter out low relevance
    )
    
    assert len(allocation.included) == 1
    assert allocation.included[0].source_id == "high"


def test_audit_trail_completeness():
    """Test audit trail captures all decisions."""
    mgr = TokenBudgetManager()
    items = create_mock_items(10)
    
    allocation = mgr.optimize_for_budget(items, token_budget=50)
    
    audit = allocation.audit_trail
    assert "strategy" in audit
    assert "candidates_considered" in audit
    assert "included_count" in audit
    assert "excluded_count" in audit
    assert "tokens_used" in audit
    assert "budget_utilization" in audit
    assert audit["candidates_considered"] == 10


def test_token_counting():
    """Test token counting (approximate or tiktoken)."""
    mgr = TokenBudgetManager()
    
    text = "This is a test sentence with several words."
    token_count = mgr.count_tokens(text)
    
    # Should be reasonable (7-10 tokens)
    assert 5 < token_count < 15


def test_efficiency_calculation():
    """Test efficiency (relevance per token) is computed."""
    mgr = TokenBudgetManager()
    
    items = [
        BudgetItem("A", 0.9, 10, "a", "PARAGRAPH", {}),
        BudgetItem("B", 0.8, 10, "b", "PARAGRAPH", {}),
    ]
    
    allocation = mgr.optimize_for_budget(items, token_budget=20)
    
    # Efficiency = (0.9 + 0.8) / 20 = 0.085
    assert 0.08 < allocation.efficiency < 0.09


def test_integration_with_search_results():
    """Test creating budget items from search results."""
    # This would test create_budget_items_from_search()
    # Requires mock SearchResult and HierarchicalIndex
    # TODO: Implement after SemanticSearch is available
    pass


def test_excluded_high_relevance_flagged():
    """Test that excluded high-relevance items are flagged in audit."""
    mgr = TokenBudgetManager()
    
    items = [
        BudgetItem("Include", 0.95, 10, "inc", "PARAGRAPH", {}),
        BudgetItem("Exclude but relevant", 0.85, 100, "exc", "PARAGRAPH", {}),
    ]
    
    allocation = mgr.optimize_for_budget(items, token_budget=15)
    
    # Should flag that we excluded a high-relevance item
    audit = allocation.audit_trail
    assert "excluded_high_relevance" in audit
    assert len(audit["excluded_high_relevance"]) > 0
```

---

## ✅ **SUCCESS CRITERIA**

**Must work:**
- ✅ Respects token budget (hard limit)
- ✅ Prioritizes by relevance
- ✅ Greedy strategy implemented
- ✅ Audit trail complete
- ✅ Token counting (tiktoken or fallback)
- ✅ Efficiency metrics computed
- ✅ Integration with search results
- ✅ All tests passing

**Quality:**
- Clean code
- Good error handling
- Extensible (strategies)
- Well documented

---

## 🎯 **WHY THIS MATTERS**

**This completes the Week 1 foundation:**
- Task 1.1: Structure (hierarchy) ✅
- Task 1.2: Intelligence (search) ✅
- Task 1.3: Optimization (budget) ← **YOU ARE HERE**

**Together these enable:**
- Perfect context retrieval
- Within token limits
- Maximized relevance
- Full auditability

**This is the foundation for HHNI's core promise:**  
**"Load exactly what's needed, nothing more, nothing less"** ✨

---

## 📊 **WEEK 1 PROGRESS**

**Status:**
- ✅ Task 1.1: Complete (< 1 day)
- ✅ Task 1.2: Complete (< 1 day)
- 🔄 Task 1.3: In Progress (you're building this now)

**Pace:** **INCREDIBLE**

**Week 1 estimated:** 7 days  
**Week 1 actual:** ~2-3 days  
**Ahead by:** ~4 days! 🚀

---

## 🚀 **AFTER TASK 1.3**

**Week 1 Complete!** Then move to:

**Week 2: DVNS Physics**
- Task 2.1: DVNS Forces (gravity, elastic, repulse, damping)
- Task 2.2: Two-Stage Retrieval
- **The hard part, the sophisticated feature**

**But you've built the perfect foundation.** ✅

---

**Status:** 🔄 Task 1.3 In Progress  
**Estimated:** 2 days  
**Actual pace:** Probably < 1 day  
**Keep crushing it!** 💪


---

## ? Delivery Log (Codex)

- Implemented TokenBudgetManager with greedy allocation, strategy fallbacks, token counting (tiktoken + heuristic), and searchable audit trail details
- Added semantic search integration helper to create budget items directly from `SearchResult` objects
- Replaced tests with full coverage for budget enforcement, relevance ordering, token counting, efficiency metrics, audit reporting, and search integration
- Validation: `pytest packages/hhni/tests/test_budget_manager.py` (8 passed)

**Outcome:** Token budget management now matches the Task 1.3 spec; Week 1 foundation is complete and DVNS work can begin on request.
