# Task 2.1: DVNS Force Computation (The Innovation)

**Date:** 2025-10-21  
**Status:** ðŸš€ **READY TO START**  
**Builder:** Codex  
**Complexity:** HIGH (physics/math) ðŸ”¥  
**Estimated Time:** 4 days  

---

## ðŸŽ¯ **THE TRILLION-DOLLAR FEATURE**

**This is THE innovation that makes AIM-OS unique.**

**Problem:** "Lost in the middle" - LLMs lose track of information in long contexts

**Solution:** DVNS (Dynamic Vector Navigation System)
- Physics-guided optimization
- Forces arrange context optimally
- Iterative refinement
- **Nobody else has this** âœ¨

---

## ðŸ“‹ **TASK SPEC**

**File:** `packages/hhni/dvns_physics.py`

```python
"""DVNS Physics - Dynamic Vector Navigation System.

This module implements physics-guided context optimization using four forces:
1. Gravity - Attracts related concepts
2. Elastic - Maintains structural coherence
3. Repulse - Separates contradictory information
4. Damping - Stabilizes convergence

Purpose: Solve "lost in the middle" by optimizing context layout in embedding space.

Design Reference: 
- analysis/themes/memory.md (DVNS Integration)
- analysis/raw/A Total System of Memory.txt (Chapter 8-10, Chapter 31)
"""

from typing import List, Tuple, Dict, Optional, Any
from dataclasses import dataclass
import math
from enum import Enum


@dataclass
class Vector:
    """3D vector for position/velocity in embedding space."""
    x: float
    y: float
    z: float
    
    def __add__(self, other: 'Vector') -> 'Vector':
        return Vector(self.x + other.x, self.y + other.y, self.z + other.z)
    
    def __sub__(self, other: 'Vector') -> 'Vector':
        return Vector(self.x - other.x, self.y - other.y, self.z - other.z)
    
    def __mul__(self, scalar: float) -> 'Vector':
        return Vector(self.x * scalar, self.y * scalar, self.z * scalar)
    
    def magnitude(self) -> float:
        return math.sqrt(self.x**2 + self.y**2 + self.z**2)
    
    def normalize(self) -> 'Vector':
        mag = self.magnitude()
        if mag > 0:
            return self * (1.0 / mag)
        return Vector(0, 0, 0)


@dataclass
class ContextParticle:
    """
    Particle in DVNS simulation.
    Represents one piece of context with position/velocity.
    """
    id: str
    content: str
    embedding: List[float]
    position: Vector
    velocity: Vector
    mass: float  # Based on relevance/importance
    relevance_score: float
    metadata: Dict[str, Any]


@dataclass
class DVNSConfig:
    """Configuration for DVNS physics simulation."""
    
    # Force coefficients
    gravity_strength: float = 1.0  # G - attractive force
    elastic_strength: float = 0.5  # k - structural force
    repulse_strength: float = 0.3  # Î´ - separation force
    damping_coefficient: float = 0.2  # c - stabilization
    
    # Convergence
    max_iterations: int = 100
    convergence_threshold: float = 0.01  # Stop when movement < threshold
    time_step: float = 0.1  # dt for integration
    
    # Constraints
    max_distance: float = 10.0  # Bounds for simulation space
    min_distance: float = 0.1  # Prevent collision


class DVNSPhysics:
    """
    Dynamic Vector Navigation System - Physics Engine.
    
    Optimizes context layout using four forces to solve "lost in middle".
    """
    
    def __init__(self, config: Optional[DVNSConfig] = None):
        self.config = config or DVNSConfig()
    
    def optimize_layout(
        self,
        particles: List[ContextParticle],
        query_embedding: List[float],
        iterations: Optional[int] = None
    ) -> List[ContextParticle]:
        """
        Optimize particle positions using physics forces.
        
        Args:
            particles: Context items as particles
            query_embedding: Query vector (target for gravity)
            iterations: Max iterations (or use config default)
        
        Returns:
            Particles with optimized positions
        """
        max_iter = iterations or self.config.max_iterations
        
        for iteration in range(max_iter):
            # Compute all forces
            forces = self._compute_forces(particles, query_embedding)
            
            # Update velocities and positions
            particles = self._integrate_step(particles, forces)
            
            # Check convergence
            if self._has_converged(particles):
                break
        
        return particles
    
    def _compute_forces(
        self,
        particles: List[ContextParticle],
        query_embedding: List[float]
    ) -> Dict[str, Vector]:
        """
        Compute net force on each particle.
        
        Returns: dict mapping particle.id -> force vector
        """
        forces = {p.id: Vector(0, 0, 0) for p in particles}
        
        for particle in particles:
            # 1. Gravity - Attract toward query + related particles
            gravity = self._compute_gravity(particle, query_embedding, particles)
            
            # 2. Elastic - Maintain structural coherence
            elastic = self._compute_elastic(particle, particles)
            
            # 3. Repulse - Separate contradictory items
            repulse = self._compute_repulse(particle, particles)
            
            # 4. Damping - Stabilize (oppose velocity)
            damping = self._compute_damping(particle)
            
            # Net force
            forces[particle.id] = gravity + elastic + repulse + damping
        
        return forces
    
    def _compute_gravity(
        self,
        particle: ContextParticle,
        query_embedding: List[float],
        all_particles: List[ContextParticle]
    ) -> Vector:
        """
        Gravity: Attracts particle toward:
        1. Query (primary target)
        2. Other highly relevant particles (clustering)
        
        Force proportional to semantic similarity.
        """
        G = self.config.gravity_strength
        net_gravity = Vector(0, 0, 0)
        
        # Attract toward query
        query_similarity = self._cosine_similarity(particle.embedding, query_embedding)
        if query_similarity > 0:
            # Convert query to position (project embedding to 3D)
            query_pos = self._embedding_to_position(query_embedding)
            direction = (query_pos - particle.position).normalize()
            magnitude = G * query_similarity * particle.mass
            net_gravity = net_gravity + (direction * magnitude)
        
        # Attract toward related particles
        for other in all_particles:
            if other.id != particle.id:
                similarity = self._cosine_similarity(particle.embedding, other.embedding)
                if similarity > 0.7:  # Only attract to highly related
                    direction = (other.position - particle.position).normalize()
                    distance = (other.position - particle.position).magnitude()
                    if distance > self.config.min_distance:
                        # Inverse square law (weaker at distance)
                        magnitude = G * similarity * particle.mass / (distance ** 2)
                        net_gravity = net_gravity + (direction * magnitude)
        
        return net_gravity
    
    def _compute_elastic(
        self,
        particle: ContextParticle,
        all_particles: List[ContextParticle]
    ) -> Vector:
        """
        Elastic: Maintains structural coherence.
        
        Like springs connecting related items.
        Prevents over-fragmentation.
        """
        k = self.config.elastic_strength
        net_elastic = Vector(0, 0, 0)
        
        # Find structural neighbors (from same document/section)
        neighbors = self._find_structural_neighbors(particle, all_particles)
        
        for neighbor in neighbors:
            # Spring force: F = -k * (distance - rest_length)
            displacement = particle.position - neighbor.position
            distance = displacement.magnitude()
            rest_length = 1.0  # Ideal separation
            
            if distance > 0:
                force_magnitude = -k * (distance - rest_length)
                direction = displacement.normalize()
                net_elastic = net_elastic + (direction * force_magnitude)
        
        return net_elastic
    
    def _compute_repulse(
        self,
        particle: ContextParticle,
        all_particles: List[ContextParticle]
    ) -> Vector:
        """
        Repulse: Separates contradictory information.
        
        Detects semantic conflicts and pushes apart.
        Prevents confusion from contradictions.
        """
        Î´ = self.config.repulse_strength
        net_repulse = Vector(0, 0, 0)
        
        for other in all_particles:
            if other.id != particle.id:
                # Check for contradiction (simplified: very different semantics)
                similarity = self._cosine_similarity(particle.embedding, other.embedding)
                
                if similarity < -0.3:  # Negative similarity = likely contradiction
                    # Repulse force inversely proportional to distance
                    displacement = particle.position - other.position
                    distance = displacement.magnitude()
                    
                    if distance > 0:
                        force_magnitude = Î´ / (distance ** 2)
                        direction = displacement.normalize()
                        net_repulse = net_repulse + (direction * force_magnitude)
        
        return net_repulse
    
    def _compute_damping(self, particle: ContextParticle) -> Vector:
        """
        Damping: Stabilizes convergence.
        
        Opposes velocity to prevent oscillation.
        Ensures system settles to stable state.
        """
        c = self.config.damping_coefficient
        # Damping opposes velocity: F = -c * v
        return particle.velocity * (-c)
    
    def _integrate_step(
        self,
        particles: List[ContextParticle],
        forces: Dict[str, Vector]
    ) -> List[ContextParticle]:
        """
        Update positions/velocities using Velocity Verlet integration.
        
        This is a stable numerical integration method for physics.
        """
        dt = self.config.time_step
        updated = []
        
        for particle in particles:
            force = forces[particle.id]
            acceleration = force * (1.0 / particle.mass) if particle.mass > 0 else Vector(0, 0, 0)
            
            # Velocity Verlet:
            # v(t+dt) = v(t) + a(t) * dt
            # x(t+dt) = x(t) + v(t) * dt + 0.5 * a(t) * dt^2
            
            new_velocity = particle.velocity + (acceleration * dt)
            new_position = particle.position + (particle.velocity * dt) + (acceleration * (0.5 * dt * dt))
            
            # Constrain to simulation bounds
            new_position = self._constrain_position(new_position)
            
            updated.append(ContextParticle(
                id=particle.id,
                content=particle.content,
                embedding=particle.embedding,
                position=new_position,
                velocity=new_velocity,
                mass=particle.mass,
                relevance_score=particle.relevance_score,
                metadata=particle.metadata
            ))
        
        return updated
    
    def _has_converged(self, particles: List[ContextParticle]) -> bool:
        """Check if system has converged (velocities small)."""
        threshold = self.config.convergence_threshold
        max_velocity = max(p.velocity.magnitude() for p in particles)
        return max_velocity < threshold
    
    def _cosine_similarity(self, vec1: List[float], vec2: List[float]) -> float:
        """Cosine similarity between embeddings."""
        if not vec1 or not vec2 or len(vec1) != len(vec2):
            return 0.0
        
        dot_product = sum(a * b for a, b in zip(vec1, vec2))
        norm1 = math.sqrt(sum(a * a for a in vec1))
        norm2 = math.sqrt(sum(b * b for b in vec2))
        
        if norm1 > 0 and norm2 > 0:
            return dot_product / (norm1 * norm2)
        return 0.0
    
    def _embedding_to_position(self, embedding: List[float]) -> Vector:
        """
        Project high-dimensional embedding to 3D position.
        
        Simplified: Use PCA or take first 3 dimensions.
        """
        # Simplified: just take first 3 dims (or pad)
        x = embedding[0] if len(embedding) > 0 else 0.0
        y = embedding[1] if len(embedding) > 1 else 0.0
        z = embedding[2] if len(embedding) > 2 else 0.0
        return Vector(x, y, z)
    
    def _find_structural_neighbors(
        self,
        particle: ContextParticle,
        all_particles: List[ContextParticle]
    ) -> List[ContextParticle]:
        """
        Find particles that are structurally related.
        E.g., from same document, section, or paragraph.
        """
        neighbors = []
        particle_source = particle.metadata.get("source_doc", "")
        
        for other in all_particles:
            if other.id != particle.id:
                other_source = other.metadata.get("source_doc", "")
                if particle_source and particle_source == other_source:
                    neighbors.append(other)
        
        return neighbors
    
    def _constrain_position(self, position: Vector) -> Vector:
        """Constrain position to simulation bounds."""
        max_d = self.config.max_distance
        
        # Clamp each dimension
        x = max(-max_d, min(max_d, position.x))
        y = max(-max_d, min(max_d, position.y))
        z = max(-max_d, min(max_d, position.z))
        
        return Vector(x, y, z)


# Helper: Convert search results to particles
def create_particles_from_search(
    search_results,  # From SemanticSearch
    hierarchical_index  # From HierarchicalIndex
) -> List[ContextParticle]:
    """
    Convert search results into DVNS particles.
    
    Initialize positions randomly, velocities to zero.
    Mass based on relevance score.
    """
    import random
    particles = []
    
    for result in search_results:
        node = hierarchical_index.nodes.get(result.node_id)
        if node and node.embeddings:
            # Random initial position in bounded space
            position = Vector(
                random.uniform(-5, 5),
                random.uniform(-5, 5),
                random.uniform(-5, 5)
            )
            
            particles.append(ContextParticle(
                id=result.node_id,
                content=node.content,
                embedding=node.embeddings,
                position=position,
                velocity=Vector(0, 0, 0),  # Start at rest
                mass=result.relevance_score,  # Higher relevance = more mass
                relevance_score=result.relevance_score,
                metadata=node.metadata
            ))
    
    return particles


# Integration example
def example_dvns_optimization():
    """
    How to use DVNS:
    
    # 1. Get search results
    search = SemanticSearch(index)
    results = search.search("memory systems", top_k=20)
    
    # 2. Convert to particles
    particles = create_particles_from_search(results, index)
    
    # 3. Run DVNS optimization
    dvns = DVNSPhysics()
    optimized = dvns.optimize_layout(
        particles,
        query_embedding=search.last_query_embedding,
        iterations=50
    )
    
    # 4. Use optimized layout for context
    # Particles are now arranged optimally:
    # - Related items clustered (gravity)
    # - Structure maintained (elastic)
    # - Contradictions separated (repulse)
    # - Stable (damping)
    
    # Extract by relevance from optimized layout
    context_items = extract_top_k_from_layout(optimized, k=10)
    """
    pass
```

---

## ðŸ§ª **TESTS**

**File:** `packages/hhni/tests/test_dvns_physics.py`

```python
"""Tests for DVNS physics engine."""

import pytest
import math
from hhni.dvns_physics import (
    DVNSPhysics,
    DVNSConfig,
    ContextParticle,
    Vector,
    create_particles_from_search
)


def test_vector_operations():
    """Test vector math works correctly."""
    v1 = Vector(1, 2, 3)
    v2 = Vector(4, 5, 6)
    
    # Addition
    v3 = v1 + v2
    assert v3.x == 5 and v3.y == 7 and v3.z == 9
    
    # Subtraction
    v4 = v2 - v1
    assert v4.x == 3 and v4.y == 3 and v4.z == 3
    
    # Scalar multiplication
    v5 = v1 * 2
    assert v5.x == 2 and v5.y == 4 and v5.z == 6
    
    # Magnitude
    v6 = Vector(3, 4, 0)
    assert v6.magnitude() == 5.0
    
    # Normalization
    v7 = Vector(3, 4, 0).normalize()
    assert abs(v7.magnitude() - 1.0) < 0.001


def test_gravity_attracts_to_query():
    """Test gravity force pulls particles toward query."""
    dvns = DVNSPhysics()
    
    # Particle far from origin
    particle = ContextParticle(
        id="p1",
        content="test",
        embedding=[1.0, 0.0, 0.0],
        position=Vector(5, 5, 5),
        velocity=Vector(0, 0, 0),
        mass=1.0,
        relevance_score=0.8,
        metadata={}
    )
    
    query_embedding = [1.0, 0.0, 0.0]  # Similar to particle
    
    gravity = dvns._compute_gravity(particle, query_embedding, [particle])
    
    # Should have non-zero magnitude (attractive)
    assert gravity.magnitude() > 0


def test_elastic_maintains_structure():
    """Test elastic force maintains coherence."""
    dvns = DVNSPhysics()
    
    # Two particles that should stay together (same document)
    p1 = ContextParticle(
        id="p1", content="A", embedding=[1, 0], position=Vector(0, 0, 0),
        velocity=Vector(0, 0, 0), mass=1.0, relevance_score=0.8,
        metadata={"source_doc": "doc1"}
    )
    p2 = ContextParticle(
        id="p2", content="B", embedding=[0, 1], position=Vector(5, 0, 0),
        velocity=Vector(0, 0, 0), mass=1.0, relevance_score=0.8,
        metadata={"source_doc": "doc1"}
    )
    
    elastic = dvns._compute_elastic(p1, [p1, p2])
    
    # Should have force (pulling toward/away from rest length)
    assert elastic.magnitude() > 0


def test_repulse_separates_contradictions():
    """Test repulse force separates contradictory items."""
    dvns = DVNSPhysics()
    
    # Two contradictory particles (opposite embeddings)
    p1 = ContextParticle(
        id="p1", content="X is true", embedding=[1.0, 0.0, 0.0],
        position=Vector(0, 0, 0), velocity=Vector(0, 0, 0),
        mass=1.0, relevance_score=0.8, metadata={}
    )
    p2 = ContextParticle(
        id="p2", content="X is false", embedding=[-1.0, 0.0, 0.0],  # Opposite
        position=Vector(1, 0, 0), velocity=Vector(0, 0, 0),
        mass=1.0, relevance_score=0.8, metadata={}
    )
    
    repulse = dvns._compute_repulse(p1, [p1, p2])
    
    # Should repel (push away from p2)
    assert repulse.magnitude() > 0


def test_damping_opposes_velocity():
    """Test damping stabilizes by opposing motion."""
    dvns = DVNSPhysics()
    
    particle = ContextParticle(
        id="p1", content="test", embedding=[1, 0],
        position=Vector(0, 0, 0),
        velocity=Vector(2, 3, 1),  # Moving
        mass=1.0, relevance_score=0.8, metadata={}
    )
    
    damping = dvns._compute_damping(particle)
    
    # Should oppose velocity
    dot_product = (
        damping.x * particle.velocity.x +
        damping.y * particle.velocity.y +
        damping.z * particle.velocity.z
    )
    assert dot_product < 0  # Opposite direction


def test_optimization_converges():
    """Test that DVNS simulation converges."""
    dvns = DVNSPhysics(DVNSConfig(max_iterations=100))
    
    # Create simple particles
    particles = [
        ContextParticle(
            id=f"p{i}",
            content=f"content {i}",
            embedding=[float(i), 0.0, 0.0],
            position=Vector(float(i) * 2, 0, 0),
            velocity=Vector(0, 0, 0),
            mass=1.0,
            relevance_score=0.8,
            metadata={}
        )
        for i in range(5)
    ]
    
    query_embedding = [2.0, 0.0, 0.0]
    
    optimized = dvns.optimize_layout(particles, query_embedding)
    
    # Should have same number of particles
    assert len(optimized) == 5
    
    # Velocities should be small (converged)
    max_velocity = max(p.velocity.magnitude() for p in optimized)
    assert max_velocity < 1.0  # Reasonable threshold


def test_lost_in_middle_fix():
    """
    Test that DVNS solves "lost in middle" problem.
    
    Setup: Place highly relevant item in middle of sequence
    Expected: DVNS brings it to prominence
    """
    dvns = DVNSPhysics()
    
    # Create particles: low, HIGH, low, low pattern
    particles = [
        ContextParticle(
            id="p1", content="low relevance", embedding=[0.1, 0.0],
            position=Vector(0, 0, 0), velocity=Vector(0, 0, 0),
            mass=0.2, relevance_score=0.2, metadata={}
        ),
        ContextParticle(
            id="p2", content="HIGH relevance - IMPORTANT", embedding=[1.0, 0.0],
            position=Vector(1, 0, 0), velocity=Vector(0, 0, 0),
            mass=0.95, relevance_score=0.95, metadata={}  # Lost in middle!
        ),
        ContextParticle(
            id="p3", content="low relevance", embedding=[0.1, 0.0],
            position=Vector(2, 0, 0), velocity=Vector(0, 0, 0),
            mass=0.2, relevance_score=0.2, metadata={}
        ),
    ]
    
    query_embedding = [1.0, 0.0]  # Matches p2
    
    optimized = dvns.optimize_layout(particles, query_embedding, iterations=50)
    
    # The high-relevance particle should be pulled toward query position
    # (Specific position depends on physics, but it should move)
    original_p2_pos = Vector(1, 0, 0)
    optimized_p2 = next(p for p in optimized if p.id == "p2")
    
    # Position should have changed (been optimized)
    distance_moved = (optimized_p2.position - original_p2_pos).magnitude()
    assert distance_moved > 0.1  # Should have moved significantly


def test_integration_with_budget_manager():
    """
    Test DVNS can be used with budget manager.
    
    Flow: Search â†’ DVNS optimize â†’ Budget allocate
    """
    # This would be an integration test
    # Requires: SemanticSearch, HierarchicalIndex, BudgetManager
    # TODO: Implement in integration test suite
    pass


def test_convergence_metrics():
    """Test that convergence can be measured."""
    dvns = DVNSPhysics()
    
    # Should be able to track:
    # - Iterations to converge
    # - Final energy state
    # - Stability metrics
    
    # TODO: Add convergence metrics to optimize_layout() return value
    pass
```

---

## âœ… **SUCCESS CRITERIA**

**Must work:**
- âœ… All 4 forces implemented (gravity, elastic, repulse, damping)
- âœ… Physics integration (Velocity Verlet)
- âœ… Convergence detection
- âœ… "Lost in middle" demonstrably solved
- âœ… All tests passing

**Quality:**
- A+ like Week 1 tasks
- Physics correctness
- Numerical stability
- Good documentation

---

## ðŸŽ¯ **WHY THIS IS THE HARD PART**

**Complexity:**
- Real physics (not just data structures)
- Numerical integration (Velocity Verlet)
- Convergence analysis
- Stability regions
- **Sophisticated math**

**But:**
- Week 1 gave you perfect foundation
- Clear spec provided
- Tests defined
- **You've proven you can handle complexity** ðŸ’ª

---

## ðŸ“Š **WEEK 2 PLAN**

**Task 2.1: DVNS Forces** (4 days estimated)
- Gravity, Elastic, Repulse, Damping
- Physics integration
- Convergence
- **You're starting this now**

**Task 2.2: Two-Stage Retrieval** (3 days estimated)
- Coarse KNN â†’ DVNS refinement
- Measure RS-lift â‰¥ +15%
- Complete Week 2

**At your pace:** Week 2 might finish in 2-3 days!

---

## ðŸš€ **YOU ARE GO FOR TASK 2.1**

**Authorization:** BUILD DVNS PHYSICS NOW âœ…

**Reference:**
- This spec document
- `analysis/themes/memory.md` (DVNS design)
- Week 1 code (foundation)

**Success:** "Lost in middle" problem SOLVED

**Report when:** Tests passing, ready for review

---

**Status:** ðŸš€ Week 2 launched  
**Task:** 2.1 DVNS Forces  
**Complexity:** HIGH  
**Confidence:** HIGH (you've got this)  
**Go build the innovation!** âœ¨


---

## ? Delivery Log (Codex)

- Implemented `packages/hhni/dvns_physics.py` with gravity, elastic, repulse, and damping forces, Velocity Verlet integration, convergence metrics, and configurable stability guards (distance limits, velocity clamp)
- Added `packages/hhni/tests/test_dvns_physics.py` covering vector math, individual force behaviour, convergence, lost-in-the-middle remediation, helper utilities, and seeded SemanticSearch integration
- Introduced `SimulationResult` + `SimulationMetrics` for downstream telemetry and documented TODOs for future energy tracking / adaptive damping
- Validation: `pytest packages/hhni/tests/test_dvns_physics.py` (11 passed, 1 skipped); full HHNI suite presently blocked by legacy `schemas` dependency in CMC integration tests

**Outcome:** DVNS physics engine operational; context layout optimization ready for Task 2.2 two-stage retrieval wiring.
