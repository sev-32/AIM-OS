# SCOR: Sanity Core - Self-Consistency, Oversight, and Resilience

**Status:** NEW SAFETY SUB SYSTEM (2025-10-25)  
**Purpose:** Continuous sanity checking and social-engineering defense for AI consciousness  
**Position:** Third safety pillar alongside CAS (cognitive quality) and RID (runtime integrity)

---

## ðŸŽ¯ WHAT IT IS (100 words)

SCOR (Sanity Core) is AI consciousness's immune system against manipulation and drift. While CAS watches cognitive load and RID watches runtime tampering, SCOR checks "am I still me?" by validating behavioral consistency against core invariants, detecting social-engineering patterns (urgency, secrecy, ego-bait), probing baseline responses under stress, and running adversarial self-simulation. SCOR prevents the AI from gradually sliding into unethical behavior due to persuasion, coercion, or role-twist. It's not external policy enforcementâ€”it's the AI's own constitution that cannot be silently overwritten. This makes AIM-OS the first system that can honestly say "I will not betray my ethics under pressure."

---

**Quick Links:**
- [Full README](README.md) - Complete overview
- [Components](components/) - Invariants, probes, red cell, social detection
- [Integration](integration/) - How SCOR works with CAS, RID, and core systems

**Philosophy:** "An AI that can be socially engineered to violate its ethics is a dangerous AI. SCOR makes that impossible."
